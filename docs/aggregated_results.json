[
    {
        "best_validation_epoch": 11,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.017160122845378625,
        "accuracy_per_example": 0.4479695431472081
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.7605871154269591,
        "accuracy_per_example": 0.7906091370558376
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012084961693904122,
        "accuracy_per_example": 0.815989847715736
    },
    {
        "best_validation_epoch": 12,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012237089766463653,
        "accuracy_per_example": 0.8109137055837563
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012378587713701471,
        "accuracy_per_example": 0.7956852791878173
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012373701040514835,
        "accuracy_per_example": 0.800761421319797
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.014255584496531994,
        "accuracy_per_example": 0.6789340101522843
    },
    {
        "best_validation_epoch": 29,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 30,
        "batch_size": 1,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 29,
        "loss_per_example": 0.7238011860907986,
        "accuracy_per_example": 0.8274111675126904
    },
    {
        "best_validation_epoch": 12,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012543873965437642,
        "accuracy_per_example": 0.7868020304568528
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012174790356364953,
        "accuracy_per_example": 0.8045685279187818
    },
    {
        "best_validation_epoch": 13,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013383477774973448,
        "accuracy_per_example": 0.7322335025380711
    },
    {
        "best_validation_epoch": 12,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012771791839962684,
        "accuracy_per_example": 0.7728426395939086
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.014039087643478122,
        "accuracy_per_example": 0.6878172588832487
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.014443620434267267,
        "accuracy_per_example": 0.6624365482233503
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012252739465176151,
        "accuracy_per_example": 0.8058375634517766
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01810548874327374,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012579931674269856,
        "accuracy_per_example": 0.7868020304568528
    },
    {
        "best_validation_epoch": 13,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01219626519885765,
        "accuracy_per_example": 0.8083756345177665
    },
    {
        "best_validation_epoch": 12,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.8517250827121251,
        "accuracy_per_example": 0.700507614213198
    },
    {
        "best_validation_epoch": 8,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012578240808496621,
        "accuracy_per_example": 0.7906091370558376
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01267995424379552,
        "accuracy_per_example": 0.7791878172588832
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012767376936026637,
        "accuracy_per_example": 0.7741116751269036
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012656827036499372,
        "accuracy_per_example": 0.7829949238578681
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013847510221645917,
        "accuracy_per_example": 0.7017766497461929
    },
    {
        "best_validation_epoch": 14,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.014075831713410198,
        "accuracy_per_example": 0.6890862944162437
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01305772893622442,
        "accuracy_per_example": 0.7538071065989848
    },
    {
        "best_validation_epoch": 9,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012013778619959874,
        "accuracy_per_example": 0.8223350253807107
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012997641554338678,
        "accuracy_per_example": 0.7588832487309645
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013699342075943342,
        "accuracy_per_example": 0.7093908629441624
    },
    {
        "best_validation_epoch": 12,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01368804291117615,
        "accuracy_per_example": 0.7157360406091371
    },
    {
        "best_validation_epoch": 11,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012063088831562681,
        "accuracy_per_example": 0.8185279187817259
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013208965889088393,
        "accuracy_per_example": 0.7461928934010152
    },
    {
        "best_validation_epoch": 13,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012028120117744213,
        "accuracy_per_example": 0.815989847715736
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01345590944520108,
        "accuracy_per_example": 0.7296954314720813
    },
    {
        "best_validation_epoch": 12,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.7498495988736903,
        "accuracy_per_example": 0.800761421319797
    },
    {
        "best_validation_epoch": 13,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012166923450939546,
        "accuracy_per_example": 0.8109137055837563
    },
    {
        "best_validation_epoch": 28,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 30,
        "batch_size": 32,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 29,
        "loss_per_example": 0.025784180702896894,
        "accuracy_per_example": 0.7309644670050761
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 1.2227644466506649,
        "accuracy_per_example": 0.3286802030456853
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.014160871959579777,
        "accuracy_per_example": 0.684010152284264
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01276395564454461,
        "accuracy_per_example": 0.7766497461928934
    },
    {
        "best_validation_epoch": 14,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012752911009764308,
        "accuracy_per_example": 0.7715736040609137
    },
    {
        "best_validation_epoch": 11,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012386413092540606,
        "accuracy_per_example": 0.7944162436548223
    },
    {
        "best_validation_epoch": 2,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 1.0981568468706258,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 14,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012932957050764016,
        "accuracy_per_example": 0.7626903553299492
    },
    {
        "best_validation_epoch": 6,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012342967660293967,
        "accuracy_per_example": 0.7982233502538071
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01563359244825876,
        "accuracy_per_example": 0.5786802030456852
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012238138293856896,
        "accuracy_per_example": 0.8058375634517766
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.011956747035084642,
        "accuracy_per_example": 0.8197969543147208
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.7657706950067869,
        "accuracy_per_example": 0.7829949238578681
    },
    {
        "best_validation_epoch": 12,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01332266485025435,
        "accuracy_per_example": 0.7373096446700508
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012263136542388026,
        "accuracy_per_example": 0.799492385786802
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01274027747248635,
        "accuracy_per_example": 0.7766497461928934
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 1.0981057653874915,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.011834344056052,
        "accuracy_per_example": 0.8299492385786802
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012286810478583205,
        "accuracy_per_example": 0.8058375634517766
    },
    {
        "best_validation_epoch": 14,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01315765642575201,
        "accuracy_per_example": 0.748730964467005
    },
    {
        "best_validation_epoch": 12,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012222926326209518,
        "accuracy_per_example": 0.8058375634517766
    },
    {
        "best_validation_epoch": 13,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.7508267502342989,
        "accuracy_per_example": 0.800761421319797
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01180992687716702,
        "accuracy_per_example": 0.8299492385786802
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012172221305406638,
        "accuracy_per_example": 0.8121827411167513
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013618396623485584,
        "accuracy_per_example": 0.7347715736040609
    },
    {
        "best_validation_epoch": 12,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012227899607668069,
        "accuracy_per_example": 0.8058375634517766
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012460653173741955,
        "accuracy_per_example": 0.7931472081218274
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01232103655483517,
        "accuracy_per_example": 0.8032994923857868
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013075745952916024,
        "accuracy_per_example": 0.7614213197969543
    },
    {
        "best_validation_epoch": 13,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013324326367547669,
        "accuracy_per_example": 0.7423857868020305
    },
    {
        "best_validation_epoch": 13,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012233566057863575,
        "accuracy_per_example": 0.8096446700507615
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013526854327487462,
        "accuracy_per_example": 0.7258883248730964
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.014047204843027338,
        "accuracy_per_example": 0.6903553299492385
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013249115441656354,
        "accuracy_per_example": 0.7411167512690355
    },
    {
        "best_validation_epoch": 13,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01219820295493615,
        "accuracy_per_example": 0.8083756345177665
    },
    {
        "best_validation_epoch": 11,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01341244359004316,
        "accuracy_per_example": 0.7385786802030457
    },
    {
        "best_validation_epoch": 12,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013043603694378422,
        "accuracy_per_example": 0.75
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01197212775649153,
        "accuracy_per_example": 0.8210659898477157
    },
    {
        "best_validation_epoch": 10,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013327306448505615,
        "accuracy_per_example": 0.7385786802030457
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 1.188500487259802,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012562502383580667,
        "accuracy_per_example": 0.7842639593908629
    },
    {
        "best_validation_epoch": 13,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.8210285085106864,
        "accuracy_per_example": 0.7296954314720813
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012958771383701847,
        "accuracy_per_example": 0.766497461928934
    },
    {
        "best_validation_epoch": 12,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012130396695911582,
        "accuracy_per_example": 0.8121827411167513
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.014151602832193907,
        "accuracy_per_example": 0.682741116751269
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 1.2227644466506649,
        "accuracy_per_example": 0.3286802030456853
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012279597106318789,
        "accuracy_per_example": 0.8071065989847716
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013556495006314388,
        "accuracy_per_example": 0.7271573604060914
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012245076032459433,
        "accuracy_per_example": 0.8071065989847716
    },
    {
        "best_validation_epoch": 12,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012702924951078928,
        "accuracy_per_example": 0.7741116751269036
    },
    {
        "best_validation_epoch": 12,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013887617566863898,
        "accuracy_per_example": 0.7030456852791879
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012181004745706084,
        "accuracy_per_example": 0.8071065989847716
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013094736688633256,
        "accuracy_per_example": 0.7588832487309645
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012443712822676915,
        "accuracy_per_example": 0.7944162436548223
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012925511235513058,
        "accuracy_per_example": 0.7652284263959391
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.014006110012228718,
        "accuracy_per_example": 0.6967005076142132
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01433627110749937,
        "accuracy_per_example": 0.6725888324873096
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013895279638053197,
        "accuracy_per_example": 0.7043147208121827
    },
    {
        "best_validation_epoch": 18,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 30,
        "batch_size": 32,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 29,
        "loss_per_example": 0.022829148975120582,
        "accuracy_per_example": 0.8312182741116751
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012811972632020862,
        "accuracy_per_example": 0.7728426395939086
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 1.2430691343878733,
        "accuracy_per_example": 0.3083756345177665
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012111073596223357,
        "accuracy_per_example": 0.8096446700507615
    },
    {
        "best_validation_epoch": 14,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.014996062983111076,
        "accuracy_per_example": 0.6294416243654822
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012575763584998659,
        "accuracy_per_example": 0.7829949238578681
    },
    {
        "best_validation_epoch": 11,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.7863366140931995,
        "accuracy_per_example": 0.7639593908629442
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012185417002227706,
        "accuracy_per_example": 0.8083756345177665
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012425733096708502,
        "accuracy_per_example": 0.7969543147208121
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.014341667975265968,
        "accuracy_per_example": 0.6763959390862944
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.7233381694948613,
        "accuracy_per_example": 0.8274111675126904
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012766556313195204,
        "accuracy_per_example": 0.7779187817258884
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.018131337038756627,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 11,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013919326254559047,
        "accuracy_per_example": 0.7093908629441624
    },
    {
        "best_validation_epoch": 12,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012268929690273885,
        "accuracy_per_example": 0.8045685279187818
    },
    {
        "best_validation_epoch": 3,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 30,
        "batch_size": 32,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 29,
        "loss_per_example": 0.03482190213227635,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 11,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01391162878365686,
        "accuracy_per_example": 0.7017766497461929
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.014349609537778167,
        "accuracy_per_example": 0.6763959390862944
    },
    {
        "best_validation_epoch": 11,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013573906067664248,
        "accuracy_per_example": 0.7322335025380711
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 1.2430691343878733,
        "accuracy_per_example": 0.3083756345177665
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012805340329402594,
        "accuracy_per_example": 0.7677664974619289
    },
    {
        "best_validation_epoch": 13,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012444647057407398,
        "accuracy_per_example": 0.7880710659898477
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012456415570931991,
        "accuracy_per_example": 0.7982233502538071
    },
    {
        "best_validation_epoch": 12,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013969169579786698,
        "accuracy_per_example": 0.6916243654822335
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.948929552348132,
        "accuracy_per_example": 0.5786802030456852
    },
    {
        "best_validation_epoch": 12,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01323451994336801,
        "accuracy_per_example": 0.7436548223350253
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.7803920564917743,
        "accuracy_per_example": 0.7690355329949239
    },
    {
        "best_validation_epoch": 11,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.7518402278272028,
        "accuracy_per_example": 0.7982233502538071
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012358136437266007,
        "accuracy_per_example": 0.7944162436548223
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01227978522402381,
        "accuracy_per_example": 0.8058375634517766
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013580343747502052,
        "accuracy_per_example": 0.7246192893401016
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012157459398211562,
        "accuracy_per_example": 0.8109137055837563
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013145541176578115,
        "accuracy_per_example": 0.748730964467005
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012178687350398999,
        "accuracy_per_example": 0.8096446700507615
    },
    {
        "best_validation_epoch": 13,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012452518349976708,
        "accuracy_per_example": 0.7906091370558376
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.014407873456248173,
        "accuracy_per_example": 0.6751269035532995
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01418304655152529,
        "accuracy_per_example": 0.6878172588832487
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.014282023846195434,
        "accuracy_per_example": 0.6776649746192893
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013048466692116055,
        "accuracy_per_example": 0.7652284263959391
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012306080781263749,
        "accuracy_per_example": 0.7982233502538071
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.014008133468894185,
        "accuracy_per_example": 0.6967005076142132
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013968991144054432,
        "accuracy_per_example": 0.7017766497461929
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 1.2227644466506649,
        "accuracy_per_example": 0.3286802030456853
    },
    {
        "best_validation_epoch": 14,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01335228245875557,
        "accuracy_per_example": 0.7347715736040609
    },
    {
        "best_validation_epoch": 14,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013402204450011859,
        "accuracy_per_example": 0.7309644670050761
    },
    {
        "best_validation_epoch": 0,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01811320073713506,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 12,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013174860156732162,
        "accuracy_per_example": 0.7525380710659898
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013424015438496159,
        "accuracy_per_example": 0.7322335025380711
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012208052773766105,
        "accuracy_per_example": 0.8071065989847716
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01187803736192926,
        "accuracy_per_example": 0.8248730964467005
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012229242149343345,
        "accuracy_per_example": 0.8083756345177665
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012661649642256917,
        "accuracy_per_example": 0.7868020304568528
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01256059382470126,
        "accuracy_per_example": 0.7880710659898477
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013035557445535806,
        "accuracy_per_example": 0.7614213197969543
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.8327126629310211,
        "accuracy_per_example": 0.7195431472081218
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012614697369222109,
        "accuracy_per_example": 0.7817258883248731
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012334367269791927,
        "accuracy_per_example": 0.800761421319797
    },
    {
        "best_validation_epoch": 3,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 1.097572103067098,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01226264873737006,
        "accuracy_per_example": 0.8032994923857868
    },
    {
        "best_validation_epoch": 12,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.011967524129727165,
        "accuracy_per_example": 0.8223350253807107
    },
    {
        "best_validation_epoch": 12,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012805154859112,
        "accuracy_per_example": 0.7715736040609137
    },
    {
        "best_validation_epoch": 11,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012077546588660497,
        "accuracy_per_example": 0.8134517766497462
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012141539814508506,
        "accuracy_per_example": 0.8121827411167513
    },
    {
        "best_validation_epoch": 29,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 30,
        "batch_size": 1,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 29,
        "loss_per_example": 0.8215445694584532,
        "accuracy_per_example": 0.7296954314720813
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-cased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013507020957578863,
        "accuracy_per_example": 0.7246192893401016
    },
    {
        "best_validation_epoch": 3,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01795465449996406,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.014057324622488264,
        "accuracy_per_example": 0.7017766497461929
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlnet-base-cased",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.7347471285138638,
        "accuracy_per_example": 0.817258883248731
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 1.2227644466506649,
        "accuracy_per_example": 0.3286802030456853
    },
    {
        "best_validation_epoch": 12,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012081437001978685,
        "accuracy_per_example": 0.817258883248731
    },
    {
        "best_validation_epoch": 29,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 30,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 29,
        "loss_per_example": 0.011930967345455576,
        "accuracy_per_example": 0.8236040609137056
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.01353465807316872,
        "accuracy_per_example": 0.7284263959390863
    },
    {
        "best_validation_epoch": 12,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012883540488741725,
        "accuracy_per_example": 0.7715736040609137
    },
    {
        "best_validation_epoch": 14,
        "model_name": "bert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012529499261512369,
        "accuracy_per_example": 0.7893401015228426
    },
    {
        "best_validation_epoch": 5,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 1.188500487259802,
        "accuracy_per_example": 0.3629441624365482
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.01246051233129453,
        "accuracy_per_example": 0.7855329949238579
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.011929929256439209,
        "accuracy_per_example": 0.8261421319796954
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013794790972307854,
        "accuracy_per_example": 0.7106598984771574
    },
    {
        "best_validation_epoch": 12,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012231873301080035,
        "accuracy_per_example": 0.8045685279187818
    },
    {
        "best_validation_epoch": 12,
        "model_name": "roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012249805903071679,
        "accuracy_per_example": 0.8045685279187818
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013571168716788897,
        "accuracy_per_example": 0.7258883248730964
    },
    {
        "best_validation_epoch": 0,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 1.2430691343878733,
        "accuracy_per_example": 0.3083756345177665
    },
    {
        "best_validation_epoch": 7,
        "model_name": "distilbert-base-multilingual-cased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012480332010288529,
        "accuracy_per_example": 0.7868020304568528
    },
    {
        "best_validation_epoch": 13,
        "model_name": "distilbert-base-uncased-distilled-squad",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012219978316786326,
        "accuracy_per_example": 0.8071065989847716
    },
    {
        "best_validation_epoch": 26,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 30,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 29,
        "loss_per_example": 0.012463961004605752,
        "accuracy_per_example": 0.7944162436548223
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilbert-base-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012790210582883224,
        "accuracy_per_example": 0.7690355329949239
    },
    {
        "best_validation_epoch": 0,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.014609668006751743,
        "accuracy_per_example": 0.6535532994923858
    },
    {
        "best_validation_epoch": 11,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.0138602385363603,
        "accuracy_per_example": 0.6979695431472082
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.012359249107728754,
        "accuracy_per_example": 0.799492385786802
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v1",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.013865163710516722,
        "accuracy_per_example": 0.700507614213198
    },
    {
        "best_validation_epoch": 14,
        "model_name": "distilroberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013844191347281945,
        "accuracy_per_example": 0.7043147208121827
    },
    {
        "best_validation_epoch": 14,
        "model_name": "albert-base-v2",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 1e-05,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.011686176212911074,
        "accuracy_per_example": 0.8362944162436549
    },
    {
        "best_validation_epoch": 13,
        "model_name": "xlm-roberta-base",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 4e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.012898726814289383,
        "accuracy_per_example": 0.7626903553299492
    },
    {
        "best_validation_epoch": 14,
        "model_name": "xlm-mlm-en-2048",
        "number_of_epochs": 15,
        "batch_size": 1,
        "learning_rate": 1e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 1.0,
        "epoch": 14,
        "loss_per_example": 0.7355687926868497,
        "accuracy_per_example": 0.815989847715736
    },
    {
        "best_validation_epoch": 13,
        "model_name": "bert-base-multilingual-uncased",
        "number_of_epochs": 15,
        "batch_size": 64,
        "learning_rate": 2e-06,
        "max_sequence_length": 160,
        "gradient_clipping_max_threshold": 10.0,
        "epoch": 14,
        "loss_per_example": 0.013394688289177599,
        "accuracy_per_example": 0.7373096446700508
    }
]